import streamlit as st

from langchain.llms import OpenAI
from langchain.callbacks import get_openai_callback
from langchain.callbacks import StreamlitCallbackHandler

from langchain.schema import (
    SystemMessage,  # ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    HumanMessage,  # äººé–“ã®è³ªå•
    AIMessage  # ChatGPTã®è¿”ç­”
)
from langchain.chat_models import ChatOpenAI


def init_page():
    # ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(
        page_title="ãƒãƒ£ãƒƒãƒˆQAã‚¢ãƒ—ãƒª",
        page_icon="ğŸ¤—"
    )
    st.header("ğŸ—£ï¸AIãƒãƒ£ãƒƒãƒˆãƒ„ãƒ¼ãƒ«")
    st.sidebar.title("Options")


def select_model():
    model = st.sidebar.selectbox(
        "ä»Šå›ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯:",
        ("GPT-3.5", "GPT-3.5-16k"))
    if model == "GPT-3.5":
        model_name = "gpt-3.5-turbo-0613"
    else:
        model_name = "gpt-3.5-turbo-16k-0613"

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã€temperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
    # åˆæœŸå€¤ã¯0.0ã€åˆ»ã¿å¹…ã¯0.1ã¨ã™ã‚‹
    temperature = st.sidebar.slider(
        "å›ç­”å†…å®¹ã®å‰µé€ æ€§:", min_value=0.0, max_value=1.0, value=0.0, step=0.01)

    return ChatOpenAI(temperature=temperature, model_name=model_name)

# ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸã¨ãã«ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´åˆæœŸåŒ–ã¨åŒã˜å‡¦ç†ã‚’èµ°ã‚‰ã›ã‚‹ã¨ã€å±¥æ­´ã‚’æ¶ˆã™


def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    if clear_button or "messages" not in st.session_state:
        st.session_state.messages = [
            SystemMessage(content="çµ¶å¯¾ã«é–¢è¥¿å¼ã§è¿”ç­”ã—ã¦ãã ã•ã„.")
        ]
        st.session_state.costs = []
        st.session_state.prompt_tokens = []
        st.session_state.answer_tokens = []


def get_answer(llm, messages):  # å›ç­”çµæœã€ã‚³ã‚¹ãƒˆãƒ»ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ¶ˆè²»é‡ã®ç®—å‡ºã‚’è¡Œã†é–¢æ•°
    with get_openai_callback() as cb:
        answer = llm(messages)
    return answer.content, cb.total_cost, cb.prompt_tokens, cb.completion_tokens


def display_chat_history():
    messages = st.session_state.get('messages', [])
    for message in messages:
        if isinstance(message, AIMessage):
            with st.chat_message('assistant'):
                st.markdown(message.content)
        elif isinstance(message, HumanMessage):
            with st.chat_message('user'):
                st.markdown(message.content)
        else:  # isinstance(message, SystemMessage):
            st.write(f"System message: {message.content}")


USD_JPY = 146.20  # ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆã‚’å®šç¾©ã—ã¾ã™ã€‚ã“ã®å€¤ã¯ç¾åœ¨ã®ç‚ºæ›¿ãƒ¬ãƒ¼ãƒˆã«ã‚ˆã£ã¦å¤‰ã‚ã‚Šã¾ã™ã€‚


def calculate_costs(USD_JPY):
    costs = st.session_state.get('costs', [])
    total_cost_jpy = sum(costs) * USD_JPY  # åˆè¨ˆã‚³ã‚¹ãƒˆã‚’æ—¥æœ¬å††ã«æ›ç®—ã—ã¾ã™ã€‚
    st.sidebar.markdown("## Costs")
    # æ›ç®—ã—ãŸåˆè¨ˆã‚³ã‚¹ãƒˆã‚’è¡¨ç¤ºã—ã¾ã™ã€‚
    st.sidebar.markdown(f"**Total cost: Â¥{total_cost_jpy:.2f}**")
    for cost in costs:
        cost_jpy = cost * USD_JPY  # å„ã‚³ã‚¹ãƒˆã‚’æ—¥æœ¬å††ã«æ›ç®—ã—ã¾ã™ã€‚
        st.sidebar.markdown(f"- Â¥{cost_jpy:.2f}")  # æ›ç®—ã—ãŸå„ã‚³ã‚¹ãƒˆã‚’è¡¨ç¤ºã—ã¾ã™ã€‚


def display_tokens():
    prompt_tokens = st.session_state.get('prompt_tokens', [])
    answer_tokens = st.session_state.get('answer_tokens', [])
    st.sidebar.markdown("## Tokens")
    st.sidebar.markdown(f"Prompt Tokens: {prompt_tokens}")
    st.sidebar.markdown(f"Completion Tokens: {answer_tokens}")


def main():
    init_page()
    llm = select_model()
    init_messages()

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ã‚’ç›£è¦–
    if user_input := st.chat_input("AIãƒãƒ£ãƒƒãƒˆãã‚“ã«èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ï¼"):
        st.session_state.messages.append(HumanMessage(content=user_input))
        with st.spinner("ChatGPT is typing ..."):
            answer, cost, prompt_token, answer_token = get_answer(
                llm, st.session_state.messages)
        st.session_state.messages.append(AIMessage(content=answer))
        st.session_state.costs.append(cost)
        st.session_state.prompt_tokens.append(prompt_token)
        st.session_state.answer_tokens.append(answer_token)

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    display_chat_history()

    # æ–™é‡‘è¨ˆç®—
    calculate_costs(USD_JPY)

    # Prompt Tokens, Completion Tokensã®è¡¨ç¤º
    display_tokens()


if __name__ == '__main__':
    main()
