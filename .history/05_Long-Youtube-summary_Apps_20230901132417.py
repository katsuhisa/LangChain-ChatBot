import streamlit as st

from langchain.chat_models import ChatOpenAI
from langchain.llms import OpenAI
from langchain.callbacks import get_openai_callback

from langchain.prompts import PromptTemplate
from langchain.chains.summarize import load_summarize_chain
from langchain.document_loaders import YoutubeLoader

from langchain.text_splitter import RecursiveCharacterTextSplitter

from urllib.parse import urlparse


def init_page():
    # ã‚¦ã‚§ãƒ–ãƒšãƒ¼ã‚¸ã®è¨­å®š
    st.set_page_config(
        page_title="Youtube Summarizer Apps",
        page_icon="ğŸš€"
    )
    st.header("Youtube Summarizer AppsğŸ¥")
    st.sidebar.title("Options")
    # st.session_state.model_name = "GPT-3.5-16k"
    st.session_state.costs = []
    st.session_state.prompt_tokens = []
    st.session_state.answer_tokens = []


def select_model():
    model = st.sidebar.radio(
        "ä»Šå›ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã¯:",
        ["GPT-3.5", "GPT-3.5-16k", "GPT-4"],
        captions=["gpt-3.5-turbo-0613", "gpt-3.5-turbo-16k-0613", "gpt-4"])
    if model == "GPT-3.5":
        st.session_state.model_name = "gpt-3.5-turbo-0613"
    elif model == "GPT-3.5-16k":
        st.session_state.model_name = "gpt-3.5-turbo-16k-0613"
    else:
        st.session_state.model_name = "gpt-4"

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã€temperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
    # åˆæœŸå€¤ã¯0.0ã€åˆ»ã¿å¹…ã¯0.1ã¨ã™ã‚‹
    temperature = st.sidebar.slider(
        "å›ç­”ã®å‰µé€ æ€§:", min_value=0.0, max_value=1.0, value=0.0, step=0.01)

    st.session_state.max_token = OpenAI.modelname_to_contextsize(
        st.session_state.model_name) - 300
    # st.session_state.overlap = st.sidebar.slider(
    #     "ãƒãƒ£ãƒ³ã‚¯é–“ã®é‡è¤‡æ–‡å­—æ•°:", min_value=0, max_value=100, value=0, step=10)
    return ChatOpenAI(temperature=temperature, model_name=st.session_state.model_name)

# ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ã‚’æŠ¼ã—ãŸã¨ãã«ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å±¥æ­´åˆæœŸåŒ–ã¨åŒã˜å‡¦ç†ã‚’èµ°ã‚‰ã›ã‚‹ã¨ã€å±¥æ­´ã‚’æ¶ˆã™


def select_n_chars():
    # n_charsãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    n_chars = st.sidebar.slider(
        "è¦ç´„ã™ã‚‹æ–‡å­—æ•°:", min_value=100, max_value=1000, value=100, step=100)
    return n_chars


# def init_messages():
#     clear_button = st.sidebar.button("Clear Conversation", key="clear")
#     if clear_button or "messages" not in st.session_state:
#         st.session_state.messages = [
#             SystemMessage(content="ç®‡æ¡æ›¸ãã§è¿”ç­”ã—ã¦ãã ã•ã„.")
#         ]
#         st.session_state.costs = []
#         st.session_state.prompt_tokens = []
#         st.session_state.answer_tokens = []

# URLå—ã‘å–ã‚Šé–¢æ•°


def get_url_input():
    url = st.text_input("Youtube URL: ", key="input")
    return url

# URLãŒæ­£ã—ã„ã‹æ¤œè¨¼ã™ã‚‹é–¢æ•°


def validate_url(url):
    try:
        result = urlparse(url)
        return all([result.scheme, result.netloc])
    except ValueError:
        return False


def calculate_costs():
    costs = st.session_state.get('costs', [])
    st.sidebar.markdown("## Costs")
    st.sidebar.markdown(f"**Total cost: ${sum(costs):.5f}**")
    for cost in costs:
        st.sidebar.markdown(f"- ${cost:.5f}")


def display_tokens():
    prompt_tokens = st.session_state.get('prompt_tokens', [])
    answer_tokens = st.session_state.get('answer_tokens', [])
    st.sidebar.markdown("## Tokens")
    st.sidebar.markdown(f"Prompt Tokens: {prompt_tokens}")
    st.sidebar.markdown(f"Completion Tokens: {answer_tokens}")


# Youtubeå‹•ç”»ã®å†…å®¹(æ­£ç¢ºã«ã¯å­—å¹•)ã‚’å–å¾—. Documentã¯LangChainã«ç›´æ¥æ¸¡ã™ã“ã¨ãŒã§ãã‚‹
def get_document(url):
    """
    # key | å‹	| èª¬æ˜
    # page_content | string | ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ç”Ÿã®ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    # metadata | dict | ãƒ†ã‚­ã‚¹ãƒˆã«é–¢ã™ã‚‹ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã™ã‚‹ãŸã‚ã®ã‚­ãƒ¼/å€¤ã‚¹ãƒˆã‚¢ï¼ˆã‚½ãƒ¼ã‚¹URLã€è‘—è€…ãªã©ï¼‰
    """
    with st.spinner("å†…å®¹èª­ã¿å–ã‚Šä¸­ ..."):
        loader = YoutubeLoader.from_youtube_url(
            url,
            add_video_info=True,  # ã‚¿ã‚¤ãƒˆãƒ«ã‚„å†ç”Ÿæ•°ã‚‚å–å¾—ã§ãã‚‹
            language=['en', 'ja']  # è‹±èªâ†’æ—¥æœ¬èªã®å„ªå…ˆé †ä½ã§å­—å¹•ã‚’å–å¾—
        )
        text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(  # Textåˆ†å‰²ã®æŒ‡ç¤º
            model_name=st.session_state.model_name,
            chunk_size=st.session_state.max_token,  # chunk(ãƒ–ãƒ­ãƒƒã‚¯)ï¼‘å˜ä½ã®æ–‡å­—æ•°
            # chunk_overlap=st.session_state.overlap,  # chunké–“ã§ã®é‡è¤‡æ–‡å­—æ•°ã€‚æ®µè½é–“ã§æ–‡è„ˆã‚’ç¶­æŒã—ãŸã„å ´åˆãªã©ã«æœ‰åŠ¹ã€‚
            chunk_overlap=0,  # chunké–“ã§ã®é‡è¤‡æ–‡å­—æ•°ã€‚æ®µè½é–“ã§æ–‡è„ˆã‚’ç¶­æŒã—ãŸã„å ´åˆãªã©ã«æœ‰åŠ¹ã€‚
        )
        # load_and_splitã§ã€é•·ã„Documentã®åˆ†å‰²ã‚’è‡ªå‹•ã§è¡Œãªã£ã¦ãã‚Œã‚‹ã€‚
        return loader.load_and_split(text_splitter=text_splitter)

# get_documentã§å–å¾—ã—ãŸå†…å®¹ã‚’è¦ç´„


def document_summarize(llm, docs):
    prompt_template = """Write a concise Japanese summary of the following transcript of Youtube Video.
    
    {text}

    - ã“ã“ã‹ã‚‰æ—¥æœ¬èªã§æ›¸ãã“ã¨
    - å¿…ãš3æ®µè½ä»¥å†…ã®ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã“ã¨:
    - å¿…ãš200æ–‡å­—ä»¥å†…ã§ç°¡æ½”ã«ã¾ã¨ã‚ã‚‹ã“ã¨
    - ç®‡æ¡æ›¸ãã§å‡ºåŠ›ã™ã‚‹ã“ã¨
    """

    PROMPT = PromptTemplate(template=prompt_template,
                            input_variables=["text"])

    with get_openai_callback() as cb:
        chain = load_summarize_chain(
            llm,  # e.g. ChatOpenAI(temperature=0)
            chain_type="stuff",
            verbose=True,  # ãƒã‚§ãƒ¼ãƒ³ã¯å®Ÿè¡Œä¸­ã«è©³ç´°ãªãƒ­ã‚°ã‚’å‡ºåŠ›
            prompt=PROMPT
        )
        response = chain({
            "input_documents": docs,
            "token_max": st.session_state.max_token  # é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰±ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«å¿…è¦
            # "overlap": st.session_state.overlap  # é•·ã„ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æ‰±ãˆã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’åˆ©ç”¨ã™ã‚‹ã‚ˆã†ã«ã™ã‚‹ãŸã‚ã«å¿…è¦
        },
            return_only_outputs=True)
    return response['output_text'], cb.total_cost, cb.prompt_tokens, cb.completion_tokens


def main():
    init_page()
    llm = select_model()
    # n_chars = select_n_chars()
    # init_messages()

    container = st.container()
    response_container = st.container()

    with container:
        url = get_url_input()
        is_valid_url = validate_url(url)
        if not is_valid_url:
            st.write('ã€€ğŸ‘†é©åˆ‡ãªURLã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚')
            output_text = None
        else:
            if url:
                document = get_document(url)
                with st.spinner("ChatGPT is typing ..."):
                    output_text, cost, prompt_token, answer_token = document_summarize(
                        llm, document)
                st.session_state.costs.append(cost)
                st.session_state.prompt_tokens.append(prompt_token)
                st.session_state.answer_tokens.append(answer_token)
            else:
                output_text = None

    if output_text:
        with response_container:
            st.markdown("## Summary")
            # st.write("è¦ç´„æ–‡å­—æ•°ï¼š", n_chars)
            st.write(output_text)
            st.markdown("---")
            st.markdown("## Original Text")
            st.write(document)

    # æ–™é‡‘è¨ˆç®—
    calculate_costs()

    # Prompt Tokens, Completion Tokensã®è¡¨ç¤º
    display_tokens()


if __name__ == '__main__':
    main()
